{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = pd.read_csv(r'MNIST_Train.csv')\n",
    "mnist = np.array(mnist)\n",
    "mnist_x = mnist[:,1:]\n",
    "mnist_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_y = mnist[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_x = mnist_x.reshape(-1, 28,28,1)\n",
    "mnist_x.shape\n",
    "mnist_x = tf.keras.utils.normalize(mnist_x)\n",
    "mnist_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_y = to_categorical(mnist_y)\n",
    "mnist_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_y[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Buliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,5), activation = 'relu', padding=\"same\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr = 1) # its not Mandatory Default is 0.01\n",
    "model.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1050/1050 [==============================] - 9s 8ms/step - loss: 0.2709 - accuracy: 0.9150 - val_loss: 0.1025 - val_accuracy: 0.9688\n",
      "Epoch 2/2\n",
      "1050/1050 [==============================] - 8s 8ms/step - loss: 0.0992 - accuracy: 0.9704 - val_loss: 0.0604 - val_accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef4842e700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(mnist_x, mnist_y, epochs = 2, validation_split= 0.2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4123    0   10    2    4    5   16    1   12   13]\n",
      " [   1 4656    9    2    6    0    6    9   37    5]\n",
      " [   0   10 4113   11    1    0    0   21    8    0]\n",
      " [   1    1   18 4258    0   32    0    3    1    8]\n",
      " [   1    6    2    0 4013    1    4    7    4   16]\n",
      " [   0    0    0    5    0 3709    6    0    4    5]\n",
      " [   4    0    0    0    5   17 4100    0    3    0]\n",
      " [   0    6   15   12    2    3    0 4336    2   23]\n",
      " [   1    3    8   40    2   16    5    5 3968   10]\n",
      " [   1    2    2   21   39   12    0   19   24 4108]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.53333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predict_x = model.predict(mnist_x)\n",
    "classes_x = np.argmax(predict_x, axis =1)\n",
    "classes_y = np.argmax(mnist_y, axis =1)\n",
    "con_mat = confusion_matrix(classes_x,classes_y)\n",
    "print(con_mat)\n",
    "acc = con_mat.diagonal().sum() *100/con_mat.sum()\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Data and then Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "mnist_x_train, mnist_x_test, mnist_y_train, mnist_y_test = train_test_split(mnist_x, mnist_y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_x_train = tf.keras.utils.normalize(mnist_x_train)\n",
    "mnist_x_test = tf.keras.utils.normalize(mnist_x_test)   # Normalize is not mandatory but its been observed it gives good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = (5,5), activation = 'relu', padding=\"same\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr = 3) # its not Mandatory Default is 0.01\n",
    "model.compile(optimizer= adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "840/840 [==============================] - 7s 8ms/step - loss: 860456.0000 - accuracy: 0.1005 - val_loss: 2.7113 - val_accuracy: 0.0955\n",
      "Epoch 2/10\n",
      "840/840 [==============================] - 6s 8ms/step - loss: 2.5838 - accuracy: 0.1009 - val_loss: 2.8089 - val_accuracy: 0.1009\n",
      "Epoch 3/10\n",
      "840/840 [==============================] - 7s 8ms/step - loss: 2.6098 - accuracy: 0.1015 - val_loss: 2.6756 - val_accuracy: 0.1016\n",
      "Epoch 4/10\n",
      "840/840 [==============================] - 6s 8ms/step - loss: 2.5746 - accuracy: 0.0997 - val_loss: 2.5684 - val_accuracy: 0.0955\n",
      "Epoch 5/10\n",
      "840/840 [==============================] - 7s 8ms/step - loss: 2.5911 - accuracy: 0.1015 - val_loss: 2.3612 - val_accuracy: 0.0964\n",
      "Epoch 6/10\n",
      "840/840 [==============================] - 7s 8ms/step - loss: 2.5999 - accuracy: 0.1022 - val_loss: 2.5927 - val_accuracy: 0.0955\n",
      "Epoch 7/10\n",
      "840/840 [==============================] - 6s 8ms/step - loss: 2.5578 - accuracy: 0.0983 - val_loss: 2.6206 - val_accuracy: 0.0955\n",
      "Epoch 8/10\n",
      "840/840 [==============================] - 6s 8ms/step - loss: 2.6307 - accuracy: 0.0980 - val_loss: 2.8012 - val_accuracy: 0.0955\n",
      "Epoch 9/10\n",
      "840/840 [==============================] - 6s 8ms/step - loss: 2.5685 - accuracy: 0.1001 - val_loss: 2.4414 - val_accuracy: 0.1009\n",
      "Epoch 10/10\n",
      "840/840 [==============================] - 6s 8ms/step - loss: 2.5648 - accuracy: 0.1045 - val_loss: 2.3683 - val_accuracy: 0.1030\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit(mnist_x_train, mnist_y_train, epochs=10, validation_split=.2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [883 927 786 903 821 786 785 880 810 819]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.476190476190476"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predict_x_test = model.predict(mnist_x_test)\n",
    "classes_x = np.argmax(predict_x_test, axis =1)\n",
    "classes_y = np.argmax(mnist_y_test, axis =1)\n",
    "con_mat = confusion_matrix(classes_x,classes_y)\n",
    "print(con_mat)\n",
    "acc = con_mat.diagonal().sum() *100/con_mat.sum()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
